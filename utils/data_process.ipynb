{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Author: HZQ\n",
    "* Last modified: 2018/12/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepared process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data offline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class process_pre_c():\n",
    "    \n",
    "    def __init__(self):\n",
    "        allocate needed folder path and path checking\n",
    "        allocate target urls\n",
    "        allocate strategy for error catch, anti-spider breaking\n",
    "    def reduce_mem(self):\n",
    "        reduce memory use by changing data type of each dataframe or other techs \n",
    "    def load_online(self):   \n",
    "        def init_spider():\n",
    "            choose creator from scrapy, request+BS and so on \n",
    "    \n",
    "        def generate_spider():\n",
    "            application of spider by choosed method\n",
    "    \n",
    "        def excute_spider():\n",
    "            excute spider object and return structual texts\n",
    "            save dataframe object named like xxx_ori\n",
    "    \n",
    "        def save_data():\n",
    "            save dataframe to \".../data_raw\"\n",
    "    def load_offline(self):\n",
    "        def read_data(big_flag):\n",
    "            if big_flag:\n",
    "                use chunksize params in read_csv\n",
    "            else:\n",
    "                read normally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## middle process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class process_mid_c():\n",
    "    def __init__(self):\n",
    "        allocate room for the variable returned by class process_pre_c\n",
    "        add variables required by the below functions\n",
    "\n",
    "    def apply_checkings(self):\n",
    "        application of serval checkings to the dataframe from statistical checking, completion, repetability, survivor bias\n",
    "    \n",
    "    def mark_correlation(self):\n",
    "        from description file extract feat descriptions of each data file\n",
    "        use graph structure or database structure to represent relationships between each dataset\n",
    "        save correlation parameters between each dataset to csv files\n",
    "    def divide_datatype(self):\n",
    "        divide data in serveral types including categorical data(nit include binary data), mixed data(need further extraction), binary data(no normalization needed), numerical data and so on\n",
    "        \n",
    "    def expand_data(self):\n",
    "        deal with outliers, record reasons annotated with date\n",
    "        deal with mixed data, record reasons annotated with date\n",
    "        deal with feats from other csv files or construct new feat, record reasons annotated with date\n",
    "        \n",
    "    def save_data(self):\n",
    "        save dataframe to \".../data_processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check data properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check statistical characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check survivor bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check time-related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divide data category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class process_last(self):   \n",
    "    def __init__(self):\n",
    "        allocate room for the variable returned by class process_mid_c\n",
    "        add variables required by the below functions\n",
    "        \n",
    "    def fill_na(self):\n",
    "        use Imputer() object from sklearn or the attribute of dataframe \".fillna(method=None, mode=None, inplace=False/True)\"\n",
    "        save dataframe to \".../data_processed\"  \n",
    "    \n",
    "    def apply_scaler(self):\n",
    "        use different scalers provided by sklearn with consideration of model feed\n",
    "        save dataframe to \".../data_processed\"\n",
    "        \n",
    "    def select_feat(self):\n",
    "        apply algorithms like RF(SL), Kmeans(UL) or PCA on data\n",
    "        save dataframe to \".../data_processed\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Parts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
